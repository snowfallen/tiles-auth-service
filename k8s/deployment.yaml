# ğŸ“¦ KUBERNETES CONFIGURATION - ĞŸĞĞ’ĞĞ˜Ğ™ Ğ ĞĞ—Ğ‘Ğ†Ğ 

---

## 1ï¸âƒ£ AUTH SERVICE DEPLOYMENT

### auth-service-deployment.yaml

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUTH SERVICE DEPLOYMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# Kubernetes Deployment Ğ´Ğ»Ñ Auth Service
#
# WHAT IS DEPLOYMENT:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Deployment = declarative way to manage Pods Ñ– ReplicaSets
#
# Key features:
# âœ… Desired state management (you declare, K8s maintains)
# âœ… Rolling updates (zero-downtime deploys)
# âœ… Rollback capability (undo bad deploys)
# âœ… Scaling (increase/decrease replicas)
# âœ… Self-healing (restarts failed pods)
#
# vs Pod:
# - Pod = single instance (manual management)
# - Deployment = manages multiple Pods (automatic)
#
# vs StatefulSet:
# - Deployment = stateless apps (auth-service)
# - StatefulSet = stateful apps (databases)
#
# DEPLOYMENT FLOW:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. Apply deployment.yaml (kubectl apply)
# 2. K8s creates ReplicaSet
# 3. ReplicaSet creates Pods (replicas: 2)
# 4. Pods start containers
# 5. Probes check health
# 6. Service routes traffic to healthy Pods

apiVersion: apps/v1
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API Version
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# apps/v1:
# - Stable API (not beta)
# - Deployment resource
# - Available since Kubernetes 1.9+
#
# Other versions:
# - v1: Core resources (Pod, Service, ConfigMap)
# - batch/v1: Jobs, CronJobs
# - networking.k8s.io/v1: Ingress

kind: Deployment
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Resource Type
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# Deployment = workload controller
#
# Other kinds:
# - Pod (single instance)
# - ReplicaSet (low-level, don't use directly)
# - StatefulSet (stateful apps)
# - DaemonSet (one pod per node)
# - Job (run to completion)

metadata:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # METADATA
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # Metadata = information about resource
  #
  # Fields:
  # - name: Resource identifier (unique Ğ² namespace)
  # - namespace: Logical grouping
  # - labels: Key-value tags (Ğ´Ğ»Ñ selection)
  # - annotations: Non-identifying metadata

  name: auth-service
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Deployment Name
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # Unique identifier Ğ² namespace
  #
  # Naming conventions:
  # âœ… Lowercase (required)
  # âœ… Hyphens (not underscores)
  # âœ… Descriptive (service-name)
  #
  # Examples:
  # âœ… auth-service
  # âœ… user-service
  # âŒ Auth-Service (uppercase)
  # âŒ auth_service (underscore)

  namespace: tiles-infra
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Namespace
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # Logical cluster partition
  #
  # Benefits:
  # âœ… Resource isolation (prod, dev, staging)
  # âœ… Access control (RBAC per namespace)
  # âœ… Resource quotas (limit usage)
  # âœ… Network policies (isolate traffic)
  #
  # Common patterns:
  # - Per environment: prod, staging, dev
  # - Per team: team-a, team-b
  # - Per app: app-1-infra, app-1-services
  #
  # tiles-infra:
  # - Infrastructure services
  # - Auth, Config, Discovery
  # - Shared across application
  #
  # If not specified:
  # Uses "default" namespace (not recommended)

  labels:
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Labels
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # Key-value pairs Ğ´Ğ»Ñ identification Ñ– selection
    #
    # Uses:
    # âœ… Selectors (Service, NetworkPolicy)
    # âœ… Grouping (kubectl get pods -l app=auth-service)
    # âœ… Monitoring (Prometheus, Grafana)
    # âœ… Debugging (filter resources)
    #
    # Best practices:
    # - Use standard labels (app, component, version)
    # - Consistent naming
    # - Meaningful values
    #
    # Standard labels (recommended):
    # - app.kubernetes.io/name
    # - app.kubernetes.io/component
    # - app.kubernetes.io/version
    # - app.kubernetes.io/part-of
    #
    # We use simplified:

    app: auth-service
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # App Label
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # Primary identifier
    # Used by Service selector
    #
    # Matches:
    # - Service selector (matchLabels)
    # - Monitoring tools
    # - Log aggregation

    component: backend
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Component Label
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # Application tier
    #
    # Values:
    # - backend (API services)
    # - frontend (UI)
    # - database (data stores)
    # - cache (Redis, Memcached)
    # - queue (RabbitMQ, Kafka)
    #
    # Uses:
    # - Network policies (allow backend â†’ database)
    # - Monitoring dashboards (group by component)
    # - Resource allocation (backends need more CPU)

spec:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # DEPLOYMENT SPEC
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # Desired state specification
  # K8s ensures actual state matches spec

  replicas: 2
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Replicas
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # Number of Pod instances to run
  #
  # WHY 2 REPLICAS:
  # âœ… High availability (one fails, one serves)
  # âœ… Load balancing (distribute requests)
  # âœ… Rolling updates (zero downtime)
  # âœ… Resource efficiency (not too many)
  #
  # Scaling considerations:
  #
  # Single replica (replicas: 1):
  # âœ… Simple
  # âœ… Less resources
  # âŒ Downtime during updates
  # âŒ No load balancing
  # âŒ Single point of failure
  #
  # Multiple replicas (replicas: 2+):
  # âœ… High availability
  # âœ… Load balancing
  # âœ… Zero-downtime updates
  # âš ï¸  More resources needed
  #
  # How many replicas:
  # - Small load: 2 (HA minimum)
  # - Medium load: 3-5 (good balance)
  # - High load: 5+ (horizontal scaling)
  #
  # Auto-scaling:
  # HorizontalPodAutoscaler (HPA):
  # - Automatic scaling based on metrics
  # - CPU, memory, custom metrics
  # - Min/max replicas
  #
  # Example HPA:
  # apiVersion: autoscaling/v2
  # kind: HorizontalPodAutoscaler
  # metadata:
  #   name: auth-service-hpa
  # spec:
  #   scaleTargetRef:
  #     apiVersion: apps/v1
  #     kind: Deployment
  #     name: auth-service
  #   minReplicas: 2
  #   maxReplicas: 10
  #   metrics:
  #   - type: Resource
  #     resource:
  #       name: cpu
  #       target:
  #         type: Utilization
  #         averageUtilization: 70
  #
  # STATELESS REQUIREMENT:
  # Auth service = stateless (JWT, Redis storage)
  # Can run multiple replicas safely:
  # âœ… No shared in-memory state
  # âœ… No local file storage
  # âœ… Session data Ğ² Redis (shared)
  #
  # If stateful:
  # - Use StatefulSet (not Deployment)
  # - Use sticky sessions (sessionAffinity)
  # - Consider master-replica pattern

  strategy:
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # UPDATE STRATEGY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # How to update Pods during deployment
    #
    # Two strategies:
    # 1. RollingUpdate (default, zero-downtime)
    # 2. Recreate (stop all, start new)

    type: RollingUpdate
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Strategy Type
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # RollingUpdate:
    # - Gradually replace old Pods Ğ· new
    # - Zero downtime (some Pods always running)
    # - Controlled rollout
    #
    # Process:
    # 1. Start new Pod (v2)
    # 2. Wait Ğ´Ğ»Ñ readiness
    # 3. Stop old Pod (v1)
    # 4. Repeat until all updated
    #
    # Benefits:
    # âœ… Zero downtime
    # âœ… Gradual rollout (detect issues early)
    # âœ… Easy rollback
    # âœ… Resource efficient (controlled surge)
    #
    # Recreate strategy (alternative):
    # type: Recreate
    #
    # Process:
    # 1. Stop ALL old Pods
    # 2. Start ALL new Pods
    #
    # When to use:
    # - Stateful apps (cannot run multiple versions)
    # - Breaking changes (incompatible versions)
    # - Development environments (speed over uptime)
    #
    # âŒ Downtime (all Pods stopped)
    # âŒ No gradual rollout
    # âœ… Simpler (no surge management)
    # âœ… Faster (parallel replacement)

    rollingUpdate:
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # ROLLING UPDATE PARAMETERS
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Control how rolling update proceeds

      maxSurge: 1
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Max Surge
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Max additional Pods during update
      #
      # Value types:
      # - Number: Absolute count (1, 2, 3)
      # - Percentage: Relative to replicas (25%, 50%)
      #
      # maxSurge: 1 (Ğ· replicas: 2):
      # - Normal: 2 Pods running
      # - During update: Max 3 Pods (2 + 1 surge)
      #
      # Update flow:
      # 1. Start: 2 old Pods running
      # 2. Create 1 new Pod (total: 3)
      # 3. New Pod ready
      # 4. Stop 1 old Pod (total: 2)
      # 5. Repeat Ğ´Ğ»Ñ second Pod
      #
      # Why maxSurge: 1:
      # âœ… Controlled resource usage (+50% peak)
      # âœ… Faster rollout (don't wait Ğ´Ğ»Ñ termination)
      # âœ… Maintains availability (extra capacity)
      #
      # Higher surge (maxSurge: 2):
      # âœ… Faster rollout (more parallel updates)
      # âš ï¸  More resources (more Pods running)
      #
      # Example Ğ· replicas: 4, maxSurge: 2:
      # - Normal: 4 Pods
      # - Peak: 6 Pods (4 + 2 surge)
      # - Update 2 Pods at once
      #
      # Percentage example:
      # maxSurge: 25%
      # - replicas: 4 â†’ surge: 1 Pod (25% of 4)
      # - replicas: 10 â†’ surge: 2-3 Pods
      #
      # Trade-offs:
      # High surge (50%, 100%):
      # âœ… Very fast rollout
      # âŒ More resources needed
      # âŒ Higher cost (temporarily)
      #
      # Low surge (1 Pod, 10%):
      # âœ… Resource efficient
      # âœ… Controlled rollout
      # âŒ Slower update

      maxUnavailable: 0
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Max Unavailable
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Max Pods unavailable during update
      #
      # Value types:
      # - Number: Absolute count (0, 1, 2)
      # - Percentage: Relative to replicas (25%, 50%)
      #
      # maxUnavailable: 0 (Ğ· replicas: 2):
      # - Always keep 2 Pods running
      # - Never terminate Pod until replacement ready
      # - Zero capacity reduction
      #
      # Update flow:
      # 1. Start: 2 old Pods running (available: 2)
      # 2. Create new Pod, wait ready (available: 2)
      # 3. Terminate old Pod (available: 2)
      # 4. Create new Pod, wait ready (available: 2)
      # 5. Terminate old Pod (available: 2)
      #
      # WHY maxUnavailable: 0:
      # âœ… Zero capacity loss (always full capacity)
      # âœ… Zero downtime (requests always served)
      # âœ… Safe rollout (no service degradation)
      #
      # Alternative: maxUnavailable: 1
      # - Allow 1 Pod to be down
      # - Faster rollout (don't wait Ğ´Ğ»Ñ ready)
      # - Reduced capacity during update
      #
      # Example Ğ· replicas: 2, maxUnavailable: 1:
      # 1. Start: 2 Pods running
      # 2. Stop 1 old Pod (only 1 running!)
      # 3. Start 1 new Pod
      # 4. Wait ready (back to 2 running)
      # 5. Repeat
      #
      # âš ï¸  Capacity reduced to 50% temporarily
      #
      # Percentage example:
      # maxUnavailable: 25%
      # - replicas: 4 â†’ allow 1 unavailable
      # - replicas: 8 â†’ allow 2 unavailable
      #
      # BEST PRACTICES:
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # High availability apps:
      # maxSurge: 1
      # maxUnavailable: 0
      # â†’ Zero downtime, controlled resources
      #
      # Fast rollout, OK Ğ· brief capacity loss:
      # maxSurge: 0
      # maxUnavailable: 1
      # â†’ Faster, less resources
      #
      # Very fast rollout:
      # maxSurge: 100%
      # maxUnavailable: 0
      # â†’ Double capacity temporarily, zero downtime
      #
      # Development environment:
      # maxSurge: 0
      # maxUnavailable: 100%
      # â†’ Stop all, start new (fastest)
      #
      # CANNOT BE BOTH ZERO:
      # maxSurge: 0 + maxUnavailable: 0 = invalid
      # â†’ Update cannot proceed (no room Ğ´Ğ»Ñ changes)

  selector:
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # POD SELECTOR
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # How Deployment finds its Pods
    #
    # Deployment doesn't directly manage Pods.
    # Instead, it creates ReplicaSet, which creates Pods.
    #
    # Selector:
    # - Defines which Pods belong to this Deployment
    # - Must match template.metadata.labels
    # - Immutable (cannot change after creation)

    matchLabels:
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Match Labels
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Label selector (equality-based)
      #
      # All labels must match (AND logic)
      #
      # Example:
      # matchLabels:
      #   app: auth-service
      #   version: v1
      #
      # Matches Pods Ğ·:
      # âœ… app=auth-service AND version=v1
      # âŒ app=auth-service only (missing version)
      # âŒ version=v1 only (missing app)
      #
      # Advanced selectors (matchExpressions):
      # matchExpressions:
      #   - key: app
      #     operator: In
      #     values:
      #       - auth-service
      #       - auth-service-v2
      #
      # Operators:
      # - In: Key Ğ² value list
      # - NotIn: Key NOT Ğ² value list
      # - Exists: Key exists (ignore value)
      # - DoesNotExist: Key doesn't exist

      app: auth-service
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # App Selector
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Primary selector label
      #
      # MUST MATCH:
      # template.metadata.labels.app
      #
      # This Deployment manages Pods Ğ· label:
      # app: auth-service
      #
      # If mismatch:
      # Deployment creates Pods Ğ°Ğ»Ğµ cannot find them
      # â†’ Stuck Ğ² creating state

  template:
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # POD TEMPLATE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # Template Ğ´Ğ»Ñ creating Pods
    #
    # This is the actual Pod specification.
    # Deployment uses this template to create Pods.
    #
    # Structure identical to Pod resource:
    # - metadata (labels, annotations)
    # - spec (containers, volumes, Ñ‚Ğ¾Ñ‰Ğ¾)

    metadata:
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # POD METADATA
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Metadata Ğ´Ğ»Ñ each Pod created

      labels:
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Pod Labels
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #
        # Labels applied to each Pod
        #
        # MUST INCLUDE:
        # All labels Ğ²Ñ–Ğ´ selector.matchLabels
        #
        # Can include additional labels:
        # - version: v1.0.0
        # - tier: backend
        # - track: stable

        app: auth-service
        # Primary label (matches selector)

        component: backend
        # Component label (organizational)

      annotations:
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Pod Annotations
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #
        # Non-identifying metadata
        # Not used Ğ´Ğ»Ñ selection (unlike labels)
        #
        # Common uses:
        # - Configuration hints (prometheus scraping)
        # - Deployment info (build number, git hash)
        # - Operational data (responsible team)
        #
        # vs Labels:
        # Labels: Identification, selection, grouping
        # Annotations: Metadata, configuration, tools

        prometheus.io/scrape: "true"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Prometheus Scrape Annotation
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #
        # Tells Prometheus to scrape metrics
        #
        # Prometheus ServiceMonitor looks Ğ´Ğ»Ñ:
        # - prometheus.io/scrape: "true"
        # - prometheus.io/port: "8084"
        # - prometheus.io/path: "/actuator/prometheus"
        #
        # If scraping enabled:
        # Prometheus sends:
        # GET http://pod-ip:8084/actuator/prometheus
        #
        # Auth service exposes metrics:
        # - JVM metrics (heap, threads)
        # - HTTP metrics (requests, latency)
        # - Custom metrics (logins, token issues)
        #
        # Alternative (ServiceMonitor CRD):
        # apiVersion: monitoring.coreos.com/v1
        # kind: ServiceMonitor
        # metadata:
        #   name: auth-service
        # spec:
        #   selector:
        #     matchLabels:
        #       app: auth-service
        #   endpoints:
        #   - port: http
        #     path: /actuator/prometheus

        prometheus.io/port: "8084"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Prometheus Port Annotation
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #
        # Port Ğ³Ğ´Ğµ Prometheus scrapes metrics
        #
        # Auth service port: 8084
        # Metrics endpoint: :8084/actuator/prometheus

        prometheus.io/path: "/actuator/prometheus"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Prometheus Path Annotation
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #
        # URL path Ğ´Ğ»Ñ metrics endpoint
        #
        # Spring Boot Actuator exposes:
        # /actuator/health â†’ Health checks
        # /actuator/metrics â†’ Metrics list
        # /actuator/prometheus â†’ Prometheus format
        #
        # Prometheus format example:
        # # HELP jvm_memory_used_bytes Used memory
        # # TYPE jvm_memory_used_bytes gauge
        # jvm_memory_used_bytes{area="heap"} 268435456.0

    spec:
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # POD SPEC
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Pod specification (containers, volumes, Ñ‚Ğ¾Ñ‰Ğ¾)

      initContainers:
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # INIT CONTAINERS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #
        # Containers that run BEFORE main container
        #
        # Use cases:
        # âœ… Wait Ğ´Ğ»Ñ dependencies (database ready?)
        # âœ… Setup tasks (download configs, migrate DB)
        # âœ… Security (fetch secrets, scan images)
        # âœ… Validation (check environment)
        #
        # Behavior:
        # - Run sequentially (one Ğ¿Ñ–ÑĞ»Ñ another)
        # - Must complete successfully (exit 0)
        # - If fail, Pod restarts (retries init containers)
        # - Main container waits Ğ´Ğ»Ñ all init containers
        #
        # Example flow:
        # 1. Init container 1: Wait Ğ´Ğ»Ñ PostgreSQL (30s)
        # 2. Init container 2: Wait Ğ´Ğ»Ñ Redis (10s)
        # 3. Main container starts (auth-service)
        #
        # vs Sidecar:
        # Init: Runs before, completes
        # Sidecar: Runs alongside, continuous
        #
        # Common patterns:
        # - wait-for-db
        # - download-config
        # - run-migrations
        # - setup-volumes

        - name: wait-for-postgres
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # WAIT FOR POSTGRESQL
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          #
          # Ensures PostgreSQL ready before starting app
          #
          # WHY NEEDED:
          # Pod might start before database ready:
          # 1. Both Pods start simultaneously
          # 2. Auth service tries to connect
          # 3. PostgreSQL still initializing
          # 4. Connection fails
          # 5. App crashes, restarts
          # 6. Repeat until PostgreSQL ready (slow!)
          #
          # With init container:
          # 1. Init container starts
          # 2. Waits Ğ´Ğ»Ñ PostgreSQL (blocks)
          # 3. PostgreSQL becomes ready
          # 4. Init container exits (success)
          # 5. Main container starts
          # 6. Connection succeeds immediately
          #
          # Benefits:
          # âœ… No connection errors
          # âœ… Faster startup (no retry loops)
          # âœ… Cleaner logs (no error spam)
          # âœ… Better UX (no failed requests)

          image: busybox:1.36
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # Image
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          #
          # Lightweight image Ğ· networking tools
          #
          # busybox:
          # - Alpine-based (tiny, ~1MB)
          # - Unix utilities (sh, nc, wget)
          # - Fast download
          # - Perfect Ğ´Ğ»Ñ init containers
          #
          # Version pinning (1.36):
          # âœ… Reproducible builds
          # âœ… Stable behavior
          # âœ… Security (known vulnerabilities)
          #
          # Alternative images:
          # - alpine:3.18 (more tools)
          # - nicolaka/netshoot (debugging)
          # - postgres:16-alpine (pg_isready)

          command:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Command
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            #
            # Command to run Ğ² container
            #
            # Format:
            # command: [executable, arg1, arg2]
            #
            # Overrides Docker ENTRYPOINT
            #
            # vs args:
            # command: Executable to run
            # args: Arguments to pass
            #
            # Example:
            # command: ["/bin/sh"]
            # args: ["-c", "echo hello"]
            # â†’ Runs: /bin/sh -c "echo hello"

            - sh
            # Shell executable
            # busybox uses sh (not bash)

            - -c
            # Run following string ÑĞº command

            - |
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # WAIT SCRIPT
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Shell script to wait Ğ´Ğ»Ñ PostgreSQL
              #
              # | = literal block scalar (YAML)
              # Preserves newlines Ñ– formatting

              echo "Waiting for PostgreSQL..."
              # Log message (visible Ğ² pod logs)
              # kubectl logs auth-service-xxx -c wait-for-postgres

              until nc -z auth-postgres.tiles-infra.svc.cluster.local 5432; do
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Check PostgreSQL Connection
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # nc = netcat (networking utility)
                # -z = zero I/O mode (scan only, no data)
                #
                # Checks if port open (accepting connections)
                #
                # Target:
                # auth-postgres.tiles-infra.svc.cluster.local
                # â”œâ”€ auth-postgres: Service name
                # â”œâ”€ tiles-infra: Namespace
                # â”œâ”€ svc: Service domain
                # â””â”€ cluster.local: Cluster domain
                #
                # Port 5432 = PostgreSQL default port
                #
                # Exit codes:
                # 0 = Connection successful (port open)
                # 1 = Connection failed (port closed/unreachable)
                #
                # until loop:
                # Repeat until command succeeds (exit 0)
                #
                # Alternative checks:
                # - pg_isready (requires postgres client)
                # - curl (HTTP health check)
                # - TCP socket connect

                echo "PostgreSQL not ready yet..."
                # Log retry attempt

                sleep 2
                # Wait 2 seconds before retry
                # Prevents spam (don't hammer PostgreSQL)
                #
                # Retry interval considerations:
                # - Too short (1s): Wastes resources, log spam
                # - Too long (10s): Slow startup
                # - 2-5s: Good balance

              done
              # Loop exits when nc succeeds

              echo "PostgreSQL is ready!"
              # Success message
              # Init container exits (exit 0)
              # Main container can start

              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # ERROR HANDLING
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # What if PostgreSQL never ready?
              #
              # Pod behavior:
              # - Init container keeps retrying (forever?)
              # - Pod stuck Ğ² Init:0/2 state
              # - restartPolicy determines next step
              #
              # restartPolicy: Always (default)
              # - Eventually exceeds backoff limit
              # - Pod enters CrashLoopBackOff
              # - K8s keeps retrying (exponential backoff)
              #
              # Timeout (optional):
              # Add timeout to script:
              #
              # TIMEOUT=300  # 5 minutes
              # ELAPSED=0
              # until nc -z ...; do
              #   if [ $ELAPSED -ge $TIMEOUT ]; then
              #     echo "Timeout waiting Ğ´Ğ»Ñ PostgreSQL"
              #     exit 1
              #   fi
              #   sleep 2
              #   ELAPSED=$((ELAPSED + 2))
              # done
              #
              # Benefits:
              # âœ… Fail fast (don't wait forever)
              # âœ… Clear error (timeout message)
              # âŒ More complex script

        - name: wait-for-redis
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # WAIT FOR REDIS
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          #
          # Similar to PostgreSQL wait
          # Ensures Redis ready before app starts
          #
          # Redis dependencies:
          # - Refresh token storage
          # - Session tracking
          # - Cache (future)
          #
          # Without wait:
          # - App tries to connect Redis
          # - Redis initializing
          # - Connection fails
          # - App crashes
          #
          # With wait:
          # - Wait Ğ´Ğ¾ Redis ready
          # - Then start app
          # - Connection succeeds

          image: busybox:1.36

          command:
            - sh
            - -c
            - |
              echo "Waiting for Redis..."

              until nc -z auth-redis.tiles-infra.svc.cluster.local 6379; do
                # Redis service: auth-redis
                # Port 6379 = Redis default

                echo "Redis not ready yet..."
                sleep 2
              done

              echo "Redis is ready!"

              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # REDIS AUTHENTICATION
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Current check:
              # Only verifies port open (TCP connection)
              #
              # Does NOT verify:
              # âŒ Redis accepts connections
              # âŒ Authentication works
              # âŒ Database operational
              #
              # Better check (Ğ· redis-cli):
              #
              # image: redis:7-alpine
              # command:
              #   - sh
              #   - -c
              #   - |
              #     until redis-cli -h auth-redis -p 6379 \
              #       -a "$REDIS_PASSWORD" ping | grep PONG; do
              #       echo "Redis not ready..."
              #       sleep 2
              #     done
              #     echo "Redis is ready!"
              #
              # env:
              #   - name: REDIS_PASSWORD
              #     valueFrom:
              #       secretKeyRef:
              #         name: auth-redis-secret
              #         key: REDIS_PASSWORD
              #
              # Benefits:
              # âœ… Verifies Redis operational
              # âœ… Tests authentication
              # âœ… Confirms PING/PONG
              #
              # Trade-offs:
              # âš ï¸  Larger image (redis-cli needed)
              # âš ï¸  Slower download
              # âœ…  More reliable check

              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # INIT CONTAINER ORDER
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Init containers run sequentially:
              # 1. wait-for-postgres (completes)
              # 2. wait-for-redis (completes)
              # 3. Main container starts
              #
              # Parallel check (faster):
              # Single init container checks both:
              #
              # - name: wait-for-dependencies
              #   command:
              #     - sh
              #     - -c
              #     - |
              #       echo "Waiting Ğ´Ğ»Ñ dependencies..."
              #       
              #       # Check PostgreSQL
              #       until nc -z auth-postgres...:5432; do
              #         echo "PostgreSQL not ready..."
              #         sleep 1
              #       done
              #       
              #       # Check Redis
              #       until nc -z auth-redis...:6379; do
              #         echo "Redis not ready..."
              #         sleep 1
              #       done
              #       
              #       echo "All dependencies ready!"
              #
              # Benefits:
              # âœ… Faster (parallel checks)
              # âœ… Single container (simpler)
              #
              # Trade-offs:
              # âš ï¸  Less modular (one script)
              # âš ï¸  Harder to debug (which failed?)

      containers:
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # MAIN CONTAINERS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #
        # Application containers (run continuously)
        #
        # vs initContainers:
        # initContainers: Run before, complete
        # containers: Run continuously, restart on failure
        #
        # Can have multiple containers (sidecar pattern):
        # - Main app container
        # - Logging sidecar
        # - Metrics exporter
        # - Security proxy

        - name: auth-service
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # AUTH SERVICE CONTAINER
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          #
          # Main application container
          # Runs Auth Service (Spring Boot)

          image: tiles/auth-service:1.0.0
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # Container Image
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          #
          # Docker image to run
          #
          # Format: [registry/]repository[:tag]
          #
          # Examples:
          # docker.io/library/nginx:1.25
          # â”œâ”€ docker.io: Registry (Docker Hub)
          # â”œâ”€ library: Organization
          # â”œâ”€ nginx: Repository
          # â””â”€ 1.25: Tag (version)
          #
          # tiles/auth-service:1.0.0
          # â”œâ”€ tiles: Organization (local)
          # â”œâ”€ auth-service: Repository
          # â””â”€ 1.0.0: Tag
          #
          # No registry = local image (Kind)
          #
          # VERSIONING:
          # â•â•â•â•â•â•â•â•â•â•
          # Tags:
          # âœ… 1.0.0 (semantic version)
          # âœ… v1.0.0-rc.1 (release candidate)
          # âœ… main-a1b2c3d (git commit)
          # âŒ latest (not reproducible)
          #
          # Why avoid :latest:
          # - Not reproducible (changes)
          # - No rollback (which version?)
          # - Cache issues (may not pull)
          #
          # Best practices:
          # âœ… Pin specific version
          # âœ… Use immutable tags
          # âœ… Track versions (git tags)
          #
          # Image building:
          # docker build -t tiles/auth-service:1.0.0 .
          # kind load docker-image tiles/auth-service:1.0.0
          #
          # Multi-stage builds:
          # - Build stage (Maven, dependencies)
          # - Runtime stage (JRE, JAR only)
          # - Smaller final image
          #
          # Registry options:
          # - Docker Hub (docker.io)
          # - GitHub Container Registry (ghcr.io)
          # - Google Container Registry (gcr.io)
          # - Amazon ECR (aws account.ecr)
          # - Private registry (registry.company.com)

          imagePullPolicy: IfNotPresent
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # Image Pull Policy
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          #
          # When to pull image Ğ²Ñ–Ğ´ registry
          #
          # Options:
          #
          # IfNotPresent (default Ğ´Ğ»Ñ tagged images):
          # - Pull if NOT on node
          # - Use local if exists
          # - Good Ğ´Ğ»Ñ development (faster)
          #
          # Always:
          # - Always pull Ğ²Ñ–Ğ´ registry
          # - Even if local exists
          # - Ensures latest version
          # - Slower (network transfer)
          # - Good Ğ´Ğ»Ñ :latest tag
          #
          # Never:
          # - Never pull Ğ²Ñ–Ğ´ registry
          # - Must exist locally
          # - Error if not found
          # - Good Ğ´Ğ»Ñ air-gapped clusters
          #
          # Why IfNotPresent (Kind):
          # âœ… Uses local images (faster)
          # âœ… No registry needed (offline)
          # âœ… Development-friendly
          #
          # Production recommendation:
          # Always (Ğ· versioned tags)
          # - Ensures consistency
          # - Pulls updates
          # - Registry as source of truth
          #
          # Image lifecycle (Kind):
          # 1. Build: docker build -t tiles/auth-service:1.0.0
          # 2. Load: kind load docker-image tiles/auth-service:1.0.0
          # 3. Deploy: kubectl apply -f deployment.yaml
          # 4. Pull policy: IfNotPresent â†’ uses loaded image
          #
          # Troubleshooting:
          # ImagePullBackOff error:
          # - Image not Ğ² registry
          # - Image not loaded (Kind)
          # - Wrong image name
          # - No pull credentials
          #
          # Check:
          # kubectl describe pod auth-service-xxx
          # â†’ Events section shows pull errors
          ports:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # CONTAINER PORTS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            #
            # Ports exposed by container
            #
            # Purpose:
            # - Documentation (which ports used)
            # - Service discovery (find ports)
            # - Network policies (allow/deny traffic)
            #
            # NOTE: This is informational!
            # Container can bind any port regardless of declaration.
            # Best practice: Declare all used ports.

            - containerPort: 8084
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Container Port Number
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Port where application listens
              #
              # Auth Service configuration:
              # server.port=8084 (application.yml)
              #
              # Application binds to:
              # http://0.0.0.0:8084
              # â†’ Listens on all interfaces
              #
              # Why 0.0.0.0 (not localhost):
              # - localhost = 127.0.0.1 (loopback only)
              # - 0.0.0.0 = all interfaces (external access)
              # - Kubernetes needs external access (Service â†’ Pod)
              #
              # Port selection:
              # - Avoid well-known ports (<1024, need root)
              # - Use service-specific (8080-9999 range)
              # - Document convention (8080=gateway, 8084=auth)
              #
              # Multiple ports:
              # - containerPort: 8084  # HTTP
              # - containerPort: 8443  # HTTPS (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
              # - containerPort: 9090  # Metrics (ĞµÑĞ»Ğ¸ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹)

              name: http
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Port Name
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Named port (optional, Ğ½Ğ¾ recommended)
              #
              # Benefits:
              # âœ… Self-documenting (clear purpose)
              # âœ… Service can reference by name
              # âœ… NetworkPolicy can use name
              #
              # Service usage:
              # spec:
              #   ports:
              #     - port: 80
              #       targetPort: http  # References name (not 8084)
              #
              # Why useful:
              # - Change port number (update one place)
              # - Multiple containers (same name, different port)
              # - Clear intention (http, https, metrics)
              #
              # Naming conventions:
              # - http, https (web traffic)
              # - grpc (gRPC services)
              # - metrics (Prometheus)
              # - health (health checks)
              # - admin (admin API)

              protocol: TCP
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Protocol
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Network protocol
              #
              # Options:
              # - TCP (default, most common)
              # - UDP (stateless, faster)
              # - SCTP (advanced, rarely used)
              #
              # TCP:
              # âœ… Reliable (guaranteed delivery)
              # âœ… Ordered (packets in order)
              # âœ… Connection-oriented
              # âœ… HTTP, HTTPS, gRPC
              #
              # UDP:
              # âœ… Fast (no handshake)
              # âœ… Low latency
              # âŒ Unreliable (packets may be lost)
              # âŒ Unordered
              # âœ… DNS, video streaming, gaming
              #
              # Auth Service = HTTP REST API = TCP

          env:
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # ENVIRONMENT VARIABLES
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Configuration Ñ‡ĞµÑ€ĞµĞ· environment variables
              #
              # Spring Boot supports:
              # - application.yml (static config)
              # - Environment variables (dynamic config)
              # - Config Server (centralized config)
              #
              # Priority (highest to lowest):
              # 1. Environment variables
              # 2. Config Server
              # 3. application.yml
              #
              # Why environment variables:
              # âœ… 12-factor app (config separate from code)
              # âœ… Environment-specific (dev, staging, prod)
              # âœ… Kubernetes-native (ConfigMap, Secret)
              # âœ… No code changes (just redeploy)
              #
              # Spring Boot naming:
              # Environment: SPRING_DATASOURCE_URL
              # Property: spring.datasource.url
              # â†’ Converts underscores to dots, lowercase

              - name: SPRING_PROFILES_ACTIVE
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Spring Profiles
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Activates Spring profile
                #
                # Profiles = environment-specific configs
                #
                # Common profiles:
                # - dev (development, verbose logging)
                # - staging (pre-production testing)
                # - prod (production, optimized)
                #
                # Profile files:
                # - application.yml (base config)
                # - application-dev.yml (dev overrides)
                # - application-prod.yml (prod overrides)
                #
                # Merged config:
                # application.yml + application-dev.yml
                #
                # Example differences:
                # dev:
                # - logging.level.root=DEBUG
                # - spring.jpa.show-sql=true
                # - No connection pooling
                #
                # prod:
                # - logging.level.root=WARN
                # - spring.jpa.show-sql=false
                # - Connection pooling enabled
                # - Caching enabled
                #
                # Multiple profiles:
                # SPRING_PROFILES_ACTIVE=dev,debug,local

                value: "dev"
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Direct Value
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Hardcoded string value
                #
                # vs valueFrom:
                # value: Literal string
                # valueFrom: Reference (ConfigMap, Secret)
                #
                # When to use value:
                # âœ… Simple constants
                # âœ… Environment identifiers
                # âœ… Flags (true/false)
                #
                # When to use valueFrom:
                # âœ… Sensitive data (passwords)
                # âœ… Shared config (multiple pods)
                # âœ… Dynamic values (service URLs)

              - name: SPRING_DATASOURCE_URL
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Database URL
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # JDBC connection string
                #
                # Format:
                # jdbc:postgresql://host:port/database
                #
                # Components:
                # - jdbc: JDBC protocol
                # - postgresql: Database type
                # - host: Server hostname/IP
                # - port: Database port (5432)
                # - database: Database name
                #
                # Why Kubernetes DNS:
                # auth-postgres.tiles-infra.svc.cluster.local
                # â”œâ”€ auth-postgres: Service name
                # â”œâ”€ tiles-infra: Namespace
                # â”œâ”€ svc: Service type
                # â””â”€ cluster.local: Cluster domain
                #
                # Short form (same namespace):
                # jdbc:postgresql://auth-postgres:5432/auth_db
                #
                # Cross-namespace (ĞµÑĞ»Ğ¸ Ğ² Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… namespace):
                # jdbc:postgresql://auth-postgres.tiles-infra:5432/auth_db
                #
                # External database (outside cluster):
                # jdbc:postgresql://db.example.com:5432/auth_db
                #
                # SSL connection (production):
                # jdbc:postgresql://host:5432/db?ssl=true&sslmode=require
                #
                # Connection pooling (automatic Ğ² Spring Boot):
                # HikariCP (default, very fast)
                # - minimumIdle: 10
                # - maximumPoolSize: 20
                # - connectionTimeout: 30000

                value: jdbc:postgresql://auth-postgres.tiles-infra.svc.cluster.local:5432/auth_db

              - name: SPRING_DATASOURCE_USERNAME
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Database Username
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # PostgreSQL user Ğ´Ğ»Ñ authentication

                valueFrom:
                  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                  # Value From Source
                  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                  #
                  # Load value Ğ²Ñ–Ğ´ external source
                  #
                  # Sources:
                  # - configMapKeyRef (ConfigMap)
                  # - secretKeyRef (Secret)
                  # - fieldRef (Pod metadata)
                  # - resourceFieldRef (Resource limits)
                  #
                  # Why valueFrom:
                  # âœ… DRY (don't repeat values)
                  # âœ… Centralized config (one place)
                  # âœ… Share Ğ¼Ñ–Ğ¶ pods
                  # âœ… Update Ğ±ĞµĞ· redeploy
                  #
                  # ConfigMap vs Secret:
                  # ConfigMap: Non-sensitive (usernames, URLs)
                  # Secret: Sensitive (passwords, tokens)

                  configMapKeyRef:
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ConfigMap Reference
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    #
                    # Load Ğ²Ñ–Ğ´ ConfigMap
                    #
                    # ConfigMap = key-value storage
                    # Non-sensitive configuration

                    name: auth-postgres-config
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ConfigMap Name
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    #
                    # Which ConfigMap to read
                    #
                    # Must exist Ğ² same namespace
                    # (tiles-infra)
                    #
                    # ConfigMap structure:
                    # apiVersion: v1
                    # kind: ConfigMap
                    # metadata:
                    #   name: auth-postgres-config
                    # data:
                    #   POSTGRES_USER: auth_user
                    #   POSTGRES_DB: auth_db

                    key: POSTGRES_USER
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ConfigMap Key
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    #
                    # Which key to extract
                    #
                    # Value: auth_user
                    #
                    # Result:
                    # SPRING_DATASOURCE_USERNAME=auth_user
                    #
                    # If key doesn't exist:
                    # Pod fails to start (error)

              - name: POSTGRES_PASSWORD
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Database Password (Sensitive!)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # PostgreSQL password
                #
                # IMPORTANT: Use Secret (not ConfigMap)
                # Passwords = sensitive data

                valueFrom:
                  secretKeyRef:
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # Secret Reference
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    #
                    # Load Ğ²Ñ–Ğ´ Kubernetes Secret
                    #
                    # Secret vs ConfigMap:
                    # âœ… Base64 encoded (obfuscation)
                    # âœ… RBAC control (who can read)
                    # âœ… Audit logging (access tracked)
                    # âœ… Encryption at rest (optional)
                    #
                    # Secret types:
                    # - Opaque (generic key-value)
                    # - kubernetes.io/tls (certificates)
                    # - kubernetes.io/dockerconfigjson (registry auth)
                    #
                    # Security best practices:
                    # âš ï¸ Secrets NOT encrypted by default
                    # âš ï¸ Stored Ğ² etcd (plain text)
                    # âœ… Enable encryption at rest
                    # âœ… Use external secret managers:
                    #    - Sealed Secrets (Bitnami)
                    #    - External Secrets Operator
                    #    - HashiCorp Vault
                    #    - AWS Secrets Manager
                    #    - Google Secret Manager

                    name: auth-postgres-secret
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # Secret Name
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    #
                    # Secret structure:
                    # apiVersion: v1
                    # kind: Secret
                    # metadata:
                    #   name: auth-postgres-secret
                    # type: Opaque
                    # stringData:
                    #   POSTGRES_PASSWORD: auth_password_change_me_in_prod

                    key: POSTGRES_PASSWORD
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # Secret Key
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    #
                    # Extract password value
                    #
                    # Result:
                    # POSTGRES_PASSWORD=auth_password_change_me_in_prod
                    #
                    # Spring Boot usage:
                    # spring:
                    #   datasource:
                    #     password: ${POSTGRES_PASSWORD}

              - name: SPRING_DATA_REDIS_HOST
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Redis Hostname
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Redis service endpoint
                #
                # Kubernetes DNS:
                # auth-redis.tiles-infra.svc.cluster.local
                #
                # Short form (same namespace):
                # auth-redis
                #
                # Redis connection:
                # Spring Boot creates connection pool
                # Lettuce (default, async I/O)
                # Ğ°Ğ±Ğ¾ Jedis (synchronous)

                value: auth-redis.tiles-infra.svc.cluster.local

              - name: SPRING_DATA_REDIS_PORT
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Redis Port
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Redis default port: 6379
                #
                # Why string "6379" (not number):
                # Environment variables = always strings
                # Spring Boot converts to integer

                value: "6379"

              - name: REDIS_PASSWORD
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Redis Password (Sensitive!)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Redis authentication
                #
                # Redis AUTH command:
                # AUTH password
                #
                # Spring Boot usage:
                # spring:
                #   data:
                #     redis:
                #       password: ${REDIS_PASSWORD}

                valueFrom:
                  secretKeyRef:
                    name: auth-redis-secret
                    key: REDIS_PASSWORD
                    # Value: redis_password_change_me_in_prod

              - name: JWT_PRIVATE_KEY
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # JWT Private Key (Very Sensitive!)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # RSA private key Ğ´Ğ»Ñ signing JWTs
                #
                # CRITICAL SECURITY:
                # âš ï¸  Never expose (compromise = full breach)
                # âš ï¸  Rotate regularly (every 90 days)
                # âš ï¸  Store securely (encrypted storage)
                # âš ï¸  Limit access (RBAC)
                #
                # Key format:
                # -----BEGIN PRIVATE KEY-----
                # MIIEvgIBADANBgkqhkiG9w0BAQEFAASCB...
                # -----END PRIVATE KEY-----
                #
                # Multi-line value Ğ² Secret:
                # stringData:
                #   JWT_PRIVATE_KEY: |
                #     -----BEGIN PRIVATE KEY-----
                #     ...
                #     -----END PRIVATE KEY-----
                #
                # Spring Boot reads:
                # jwt.private-key=${JWT_PRIVATE_KEY}

                valueFrom:
                  secretKeyRef:
                    name: jwt-keys-secret
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # JWT Keys Secret
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    #
                    # Contains both keys:
                    # - JWT_PRIVATE_KEY (signing)
                    # - JWT_PUBLIC_KEY (validation)
                    #
                    # Why separate secret:
                    # âœ… Grouped keys (related data)
                    # âœ… Access control (limit who reads)
                    # âœ… Rotation (update both together)

                    key: JWT_PRIVATE_KEY

              - name: JWT_PUBLIC_KEY
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # JWT Public Key
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # RSA public key Ğ´Ğ»Ñ verifying JWTs
                #
                # Published via JWKS endpoint:
                # GET /.well-known/jwks.json
                #
                # Gateway uses Ğ´Ğ»Ñ validation
                #
                # Safe to expose (public key cryptography):
                # âœ… Cannot derive private key
                # âœ… Only verifies signatures
                #
                # Key format:
                # -----BEGIN PUBLIC KEY-----
                # MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8A...
                # -----END PUBLIC KEY-----

                valueFrom:
                  secretKeyRef:
                    name: jwt-keys-secret
                    key: JWT_PUBLIC_KEY

              - name: SPRING_CLOUD_CONFIG_URI
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Config Server URL
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Spring Cloud Config Server endpoint
                #
                # Centralized configuration:
                # - Shared config (database URLs)
                # - Environment-specific (dev, prod)
                # - Dynamic updates (refresh scope)
                # - Version control (Git backend)
                #
                # Config Server URL:
                # http://config-service.tiles-infra.svc.cluster.local:8888
                #
                # Application fetches config:
                # 1. Spring Boot starts
                # 2. Connects to Config Server
                # 3. Requests: /auth-service/dev
                # 4. Config Server returns properties
                # 5. Merges Ğ· local application.yml
                #
                # Priority:
                # 1. Environment variables (highest)
                # 2. Config Server
                # 3. application.yml (lowest)
                #
                # Why Config Server:
                # âœ… Centralized (one source of truth)
                # âœ… Dynamic (no redeploy needed)
                # âœ… Versioned (Git history)
                # âœ… Encrypted (sensitive values)
                #
                # Without Config Server:
                # - Config Ğ² each service
                # - Duplicate values
                # - Hard to update (redeploy all)
                #
                # Config Server alternatives:
                # - Consul (HashiCorp)
                # - etcd (CoreOS)
                # - ZooKeeper (Apache)

                value: http://config-service.tiles-infra.svc.cluster.local:8888

          resources:
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # RESOURCE LIMITS
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # CPU Ñ– memory allocation
              #
              # Two levels:
              # - requests: Guaranteed minimum
              # - limits: Maximum allowed
              #
              # Why needed:
              # âœ… Prevent resource starvation
              # âœ… Fair scheduling (Pods balanced)
              # âœ… Stability (no OOM kills)
              # âœ… Cost control (predictable usage)
              #
              # Without limits:
              # - Pod can consume all node resources
              # - Other Pods starve
              # - Node crashes (OOM)
              #
              # Kubernetes QoS Classes:
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Guaranteed (highest priority):
              # - requests = limits
              # - Never evicted (unless exceeds limits)
              #
              # Burstable (medium priority):
              # - requests < limits
              # - Can burst to limits
              # - Evicted if node under pressure
              #
              # BestEffort (lowest priority):
              # - No requests Ğ°Ğ±Ğ¾ limits
              # - First to be evicted
              # - Not recommended (unpredictable)
              #
              # This config = Burstable:
              # requests: 512Mi/250m
              # limits: 1Gi/1000m

              requests:
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Resource Requests
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Guaranteed minimum resources
                #
                # Kubernetes scheduler:
                # 1. Pod needs 512Mi memory, 250m CPU
                # 2. Scheduler finds node Ğ· available:
                #    - Memory: 512Mi+ free
                #    - CPU: 250m+ free
                # 3. Schedules Pod on that node
                # 4. Resources reserved (not available Ğ´Ğ»Ñ others)
                #
                # If no node has resources:
                # Pod stuck Ğ² Pending state
                # Event: "Insufficient memory/cpu"

                memory: "512Mi"
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Memory Request
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Guaranteed memory
                #
                # Units:
                # - Ki/Mi/Gi (binary, 1024-based)
                # - K/M/G (decimal, 1000-based)
                #
                # Examples:
                # - 512Mi = 512 * 1024^2 bytes = 536,870,912 bytes
                # - 1Gi = 1024Mi = 1,073,741,824 bytes
                # - 500M = 500 * 1000^2 bytes = 500,000,000 bytes
                #
                # Why 512Mi Ğ´Ğ»Ñ Auth Service:
                # - Spring Boot Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¸Ğ¹: ~200Mi
                # - JVM heap: ~300Mi
                # - Liquibase migrations: +100Mi
                # - Buffer: +100Mi
                # Total: ~500-600Mi
                #
                # JVM heap settings:
                # -Xms256m (initial heap)
                # -Xmx768m (max heap, 75% of limit)
                #
                # Why not full 1Gi:
                # - Leave room Ğ´Ğ»Ñ non-heap memory
                # - Native memory (threads, metaspace)
                # - OS buffers
                # - Safety margin
                #
                # Memory issues:
                # OOMKilled (Out of Memory):
                # - Pod exceeds limit
                # - Kubernetes kills pod
                # - Pod restarts (CrashLoopBackOff)
                #
                # Prevention:
                # âœ… Set appropriate limits
                # âœ… Monitor memory usage
                # âœ… Tune JVM heap
                # âœ… Fix memory leaks

                cpu: "250m"
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # CPU Request
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Guaranteed CPU time
                #
                # Units:
                # - m (millicores, 1000m = 1 core)
                # - Number (cores, 0.5 = 500m)
                #
                # Examples:
                # - 250m = 0.25 cores = 25% of one core
                # - 1000m = 1 core = 100% of one core
                # - 2 = 2000m = 2 cores
                #
                # CPU vs Memory:
                # Memory: Hard limit (OOM kill if exceeded)
                # CPU: Soft limit (throttled, but not killed)
                #
                # CPU throttling:
                # - Pod uses more than limit
                # - Kubernetes throttles (slows down)
                # - Pod not killed (continues running)
                # - Requests slower (increased latency)
                #
                # Why 250m Ğ´Ğ»Ñ Auth Service:
                # - Low traffic: 100-200m
                # - Medium traffic: 200-400m
                # - High traffic: 400-800m
                # - Burst capacity: up to 1000m (limit)
                #
                # Request = average usage
                # Limit = peak usage
                #
                # CPU shares:
                # Requests determine CPU share weight
                # - Pod A: 250m request
                # - Pod B: 500m request
                # - Pod B gets 2x CPU time
                #
                # Monitoring:
                # kubectl top pod auth-service-xxx
                # â†’ Shows actual CPU/memory usage
                #
                # Optimization:
                # - Too low: Throttling (slow)
                # - Too high: Wasted resources
                # - Right-size: Monitor Ñ– adjust

              limits:
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Resource Limits
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Maximum resources allowed
                #
                # Cannot exceed limits:
                # - Memory: OOMKilled (pod killed)
                # - CPU: Throttled (slowed down)

                memory: "1Gi"
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Memory Limit
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Maximum memory
                #
                # 1Gi = 1024Mi
                # Double of request (512Mi)
                #
                # Allows bursting:
                # - Normal: 512Mi (request)
                # - Peak: 1Gi (limit)
                # - Burst capacity: 512Mi
                #
                # Why 1Gi:
                # - Spring Boot normal: 500-700Mi
                # - Peak (traffic spike): 800-900Mi
                # - Safety margin: 100Mi
                #
                # Memory leak protection:
                # If memory keeps growing:
                # - Reaches 1Gi
                # - Kubernetes kills pod
                # - Pod restarts (fresh memory)
                #
                # OOMKilled scenario:
                # 1. Memory leak (bug)
                # 2. Memory usage: 512Mi â†’ 1Gi
                # 3. Reaches limit
                # 4. OOMKilled
                # 5. Pod restarts
                # 6. Repeat (CrashLoopBackOff)
                #
                # Prevention:
                # âœ… Fix memory leaks (profiling)
                # âœ… Limit object caching
                # âœ… Tune garbage collection
                # âœ… Monitor memory trends

                cpu: "1000m"
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # CPU Limit
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Maximum CPU
                #
                # 1000m = 1 full core
                # 4x of request (250m)
                #
                # CPU burstable:
                # - Normal: 250m (25% core)
                # - Peak: 1000m (100% core)
                # - Burst capacity: 750m
                #
                # Why 1000m:
                # - Normal load: 200-400m
                # - Traffic spike: 600-800m
                # - Max burst: 1000m (1 core)
                #
                # CPU throttling:
                # If tries to use > 1000m:
                # - Kubernetes throttles
                # - Slows down execution
                # - Requests take longer
                # - No crash (unlike memory)
                #
                # Monitoring throttling:
                # kubectl top pod auth-service-xxx
                # â†’ If CPU at limit + slow â†’ throttled
                #
                # Solution:
                # - Increase limit
                # - Optimize code (reduce CPU)
                # - Scale horizontally (more replicas)

          livenessProbe:
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # LIVENESS PROBE
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # "Is application alive?"
              #
              # Checks if application responsive
              # If fails â†’ Kubernetes restarts pod
              #
              # Purpose:
              # âœ… Detect deadlocks (app frozen)
              # âœ… Detect infinite loops (app stuck)
              # âœ… Detect crashed app (process alive but broken)
              # âœ… Self-healing (automatic restart)
              #
              # vs Readiness:
              # Liveness: Is app broken? â†’ Restart
              # Readiness: Is app ready? â†’ Don't send traffic
              #
              # When to restart:
              # - Deadlock (threads blocked)
              # - Memory exhaustion (OOM imminent)
              # - Database connection lost (cannot recover)
              # - Critical error (application broken)
              #
              # Probe types:
              # - httpGet (HTTP request)
              # - tcpSocket (TCP connection)
              # - exec (command execution)
              # - grpc (gRPC health check)

              httpGet:
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # HTTP GET Probe
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Makes HTTP request
                #
                # Success: 200-399 response code
                # Failure: Other codes, timeout, connection error

                path: /actuator/health/liveness
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Liveness Endpoint
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Spring Boot Actuator endpoint
                #
                # Returns:
                # {
                #   "status": "UP"
                # }
                #
                # Checks:
                # âœ… Application context loaded
                # âœ… Critical beans initialized
                # âœ… No deadlocks detected
                #
                # Does NOT check:
                # âŒ Database connectivity (Ğ½Ğµ Ğ´Ğ»Ñ liveness)
                # âŒ External services (Ğ½Ğµ Ğ´Ğ»Ñ liveness)
                # âŒ Cache status (Ğ½Ğµ Ğ´Ğ»Ñ liveness)
                #
                # Why minimal checks:
                # - Liveness â†’ restart decision
                # - Restart = disruptive (downtime)
                # - Only restart if truly broken
                # - Don't restart Ğ´Ğ»Ñ temporary issues
                #
                # Example bad liveness:
                # Check database connection
                # â†’ Database temporarily down
                # â†’ Liveness fails
                # â†’ Pod restarts
                # â†’ Still no database
                # â†’ Liveness fails again
                # â†’ CrashLoopBackOff
                # âŒ Cascading failure!
                #
                # Good liveness:
                # Check only application health
                # â†’ Database down (temporary)
                # â†’ Liveness succeeds (app alive)
                # â†’ Readiness fails (don't send traffic)
                # â†’ Database recovers
                # â†’ Readiness succeeds
                # âœ… No restart needed!

                port: 8084
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Probe Port
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Port to probe
                #
                # Can be:
                # - Number: 8084
                # - Name: http (references containerPort name)
                #
                # Using name (better):
                # port: http
                # â†’ Change port Ğ² one place

              initialDelaySeconds: 60
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Initial Delay
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Wait before first probe
              #
              # 60 seconds = allow slow startup
              #
              # Auth Service startup:
              # 1. JVM initialization (5-10s)
              # 2. Spring Boot context (10-20s)
              # 3. Liquibase migrations (10-30s)
              # 4. Connection pools (5s)
              # 5. Ready (total: ~30-60s)
              #
              # Why 60s:
              # âœ… Covers normal startup
              # âœ… Includes Liquibase time
              # âœ… Prevents premature restarts
              #
              # Too short (10s):
              # - Probe during startup
              # - Fails (app not ready)
              # - Restart
              # - Never finishes startup
              # - CrashLoopBackOff
              #
              # Too long (300s):
              # - Slow failure detection
              # - Broken pod runs longer
              # - Longer downtime
              #
              # Startup probe (better alternative):
              # Use startupProbe Ğ´Ğ»Ñ slow startup
              # Then short livenessProbe delay

              periodSeconds: 10
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Period
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # How often to probe (seconds)
              #
              # Every 10 seconds = check health
              #
              # Trade-off:
              # Short (5s):
              # âœ… Fast failure detection
              # âŒ More overhead (frequent requests)
              #
              # Long (30s):
              # âœ… Less overhead
              # âŒ Slow failure detection
              #
              # 10s = good balance
              # - Detect failures quickly
              # - Reasonable overhead

              timeoutSeconds: 5
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Timeout
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Max time to wait Ğ´Ğ»Ñ response
              #
              # 5 seconds timeout
              #
              # If slower than 5s:
              # - Probe fails (timeout)
              # - Counts ĞºÑŠĞ¼ failure threshold
              #
              # Why 5s:
              # - Health endpoint should be fast (<100ms)
              # - 5s allows Ğ´Ğ»Ñ temporary slowness
              # - Network delays
              #
              # If timing out:
              # - Check endpoint performance
              # - Increase timeout (last resort)
              # - Fix slow health checks

              failureThreshold: 3
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Failure Threshold
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Consecutive failures before action
              #
              # 3 failures = restart pod
              #
              # Failure sequence:
              # 1. Probe 1: Fails
              # 2. Wait 10s (periodSeconds)
              # 3. Probe 2: Fails
              # 4. Wait 10s
              # 5. Probe 3: Fails
              # 6. Restart pod (after 30s total)
              #
              # Why 3 (not 1):
              # âœ… Avoids false positives (temporary glitches)
              # âœ… Allows brief slowness
              # âœ… More stable (less restarts)
              #
              # Trade-off:
              # Low (1):
              # âœ… Fast reaction
              # âŒ Many false positives
              # âŒ Unstable (frequent restarts)
              #
              # High (10):
              # âœ… Very stable
              # âŒ Slow detection (100s)
              # âŒ Broken pod runs longer
              #
              # 3 = good default
              # Detection time: 30s (3 * 10s)

          readinessProbe:
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # READINESS PROBE
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # "Is application ready to serve traffic?"
              #
              # Checks if application can handle requests
              # If fails â†’ Remove Ğ²Ñ–Ğ´ Service endpoints
              #
              # Purpose:
              # âœ… Zero-downtime deployments
              # âœ… Graceful startup (wait Ğ´Ğ¾ ready)
              # âœ… Graceful shutdown (drain connections)
              # âœ… Dependency checks (database, cache)
              #
              # vs Liveness:
              # Liveness: Restart if broken
              # Readiness: Don't send traffic if not ready
              #
              # Traffic routing:
              # Ready: Service sends traffic â†’ Pod
              # Not ready: Service skips pod â†’ Other pods
              #
              # Deployment rollout:
              # 1. New pod starts
              # 2. Readiness: Not ready (don't send traffic)
              # 3. Application initializes
              # 4. Dependencies check (DB, Redis)
              # 5. Readiness: Ready (send traffic)
              # 6. Old pod terminates
              # â†’ Zero downtime!

              httpGet:
                path: /actuator/health/readiness
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Readiness Endpoint
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Spring Boot Actuator endpoint
                #
                # Checks:
                # âœ… Database connectivity (can query?)
                # âœ… Redis connectivity (can connect?)
                # âœ… Config Server (configuration loaded?)
                # âœ… All dependencies ready
                #
                # Returns:
                # {
                #   "status": "UP",
                #   "components": {
                #     "db": {"status": "UP"},
                #     "redis": {"status": "UP"},
                #     "ping": {"status": "UP"}
                #   }
                # }
                #
                # If any component DOWN:
                # {
                #   "status": "DOWN",
                #   "components": {
                #     "db": {"status": "DOWN", "details": {...}}
                #   }
                # }
                #
                # Detailed checks:
                # âœ… Can execute SELECT 1 (database)
                # âœ… Can PING (Redis)
                # âœ… Connection pools healthy
                #
                # vs Liveness:
                # Liveness: Minimal checks (app alive?)
                # Readiness: Full checks (all dependencies ready?)

                port: 8084

              initialDelaySeconds: 30
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Initial Delay
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # 30 seconds before first readiness check
              #
              # Shorter than liveness (60s):
              # - Readiness doesn't restart (safer)
              # - Check earlier (route traffic sooner)
              #
              # Startup sequence:
              # 0s: Container starts
              # 30s: First readiness check
              # 60s: First liveness check
              #
              # Why 30s:
              # - Spring Boot context loaded (~20s)
              # - Liquibase might still run
              # - Not critical (just delays traffic)

              periodSeconds: 5
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Period
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Check every 5 seconds
              #
              # More frequent than liveness (10s):
              # âœ… Faster traffic rerouting
              # âœ… Quick response to issues
              # âœ… Smoother deployments
              #
              # Safe to probe often:
              # - Readiness doesn't restart
              # - Only affects traffic routing

              timeoutSeconds: 3
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Timeout
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # 3 seconds timeout
              #
              # Shorter than liveness (5s):
              # - Readiness checks dependencies
              # - Should be fast (< 1s)
              # - 3s allows network delays

              failureThreshold: 3
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Failure Threshold
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # 3 consecutive failures â†’ Not ready
              #
              # Total time to unready: 15s (3 * 5s)
              #
              # Recovery:
              # Once succeeds â†’ Ready again
              # successThreshold: 1 (default)

          startupProbe:
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # STARTUP PROBE
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # "Has application finished starting?"
              #
              # Special probe Ğ´Ğ»Ñ slow startup apps
              #
              # Purpose:
              # âœ… Protects slow startup (Liquibase migrations)
              # âœ… Prevents premature liveness failures
              # âœ… Allows long initialization
              # âœ… Enables fast liveness Ğ¿Ñ–ÑĞ»Ñ startup
              #
              # How it works:
              # 1. Startup probe active (liveness disabled)
              # 2. Checks until succeeds
              # 3. Once succeeds â†’ Startup complete
              # 4. Liveness probe takes over
              #
              # Timeline:
              # 0s: Container starts
              # 0-150s: Startup probe checks (max 30 * 5s)
              # 150s: Startup succeeds or fails
              # 150s+: Liveness probe active
              #
              # Why needed Ğ´Ğ»Ñ Auth Service:
              # - Liquibase migrations variable time
              # - First run: Create all tables (30-60s)
              # - Subsequent: Quick (5-10s)
              # - Don't want liveness to fail during migration

              httpGet:
                path: /actuator/health/liveness
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # Startup Endpoint
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                #
                # Same ÑĞº liveness
                # Just checks if app responded
                #
                # Alternative: Dedicated endpoint
                # /actuator/health/startup
                #
                # Could check:
                # - Database schema ready
                # - Migrations complete
                # - All beans initialized

                port: 8084

              initialDelaySeconds: 0
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Initial Delay
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Start checking immediately (0s)
              #
              # No delay needed:
              # - Startup probe expects slow start
              # - Many retries allowed (failureThreshold: 30)
              # - Can afford to check early

              periodSeconds: 5
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Period
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Check every 5 seconds
              #
              # Frequent checks:
              # âœ… Detect startup completion quickly
              # âœ… Enable liveness sooner

              timeoutSeconds: 3
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Timeout
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # 3 seconds timeout
              #
              # Same ÑĞº readiness (reasonable)

              failureThreshold: 30
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Failure Threshold
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              #
              # Allow 30 failures before giving up
              #
              # Max startup time:
              # 30 failures * 5s period = 150 seconds
              #
              # Timeline:
              # 0s: First check (fails - still starting)
              # 5s: Check 2 (fails)
              # ...
              # 145s: Check 30 (fails)
              # 150s: Startup failed â†’ Pod killed
              #
              # Why 30:
              # âœ… Covers slow Liquibase migrations
              # âœ… Handles variable startup time
              # âœ… Still fails eventually (not forever)
              #
              # If startup completes earlier (60s):
              # - Check 1-12: Fail (0-60s)
              # - Check 13: Success! (60s)
              # - Startup probe stops
              # - Liveness probe activates
              #
              # Benefits:
              # âœ… Long startup allowed (150s max)
              # âœ… Fast liveness Ğ¿Ñ–ÑĞ»Ñ startup (10s period)
              # âœ… Best of both worlds

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # AUTH SERVICE SERVICE
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          #
          # Kubernetes Service - stable network endpoint Ğ´Ğ»Ñ Auth Service

---

apiVersion: v1
kind: Service
metadata:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # SERVICE METADATA
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  name: auth-service
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Service Name
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # DNS name Ğ´Ğ»Ñ service
  #
  # Full DNS:
  # auth-service.tiles-infra.svc.cluster.local
  # â”œâ”€ auth-service: Service name
  # â”œâ”€ tiles-infra: Namespace
  # â”œâ”€ svc: Service type
  # â””â”€ cluster.local: Cluster domain
  #
  # Short forms (from same namespace):
  # - auth-service (same namespace)
  # - auth-service.tiles-infra (cross-namespace)
  #
  # Used by:
  # - Gateway: http://auth-service:8084
  # - Config Server: http://config-service:8888
  # - Other services: http://auth-service:8084
  #
  # Why stable endpoint:
  # Pods ephemeral (IPs change):
  # - Pod dies â†’ New pod, new IP
  # - Scale up â†’ New pods, new IPs
  # - Scale down â†’ Pods removed
  #
  # Service stable:
  # - DNS name constant (auth-service)
  # - IP address stable (ClusterIP)
  # - Load balances across pods
  # - Healthy pods only

  namespace: tiles-infra
  # Same namespace ÑĞº Deployment

  labels:
    app: auth-service
    component: backend
    # Labels Ğ´Ğ»Ñ organizational purposes
    # Not used Ğ´Ğ»Ñ selection (selector below)

spec:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # SERVICE SPEC
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  type: ClusterIP
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # SERVICE TYPE
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # How service exposed
  #
  # Service Types:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # ClusterIP (this one):
  # âœ… Internal only (cluster access)
  # âœ… Stable virtual IP (ClusterIP)
  # âœ… DNS name (auth-service)
  # âœ… Load balancing (across pods)
  # âŒ No external access
  #
  # Use cases:
  # - Backend services (APIs)
  # - Databases (PostgreSQL, Redis)
  # - Internal microservices
  #
  # Access:
  # curl http://auth-service.tiles-infra:8084/auth/login
  # (Only from inside cluster)
  #
  # Why ClusterIP Ğ´Ğ»Ñ Auth Service:
  # âœ… Internal service (no direct external access)
  # âœ… Gateway routes traffic (external â†’ gateway â†’ auth)
  # âœ… Security (not exposed directly)
  # âœ… Standard microservices pattern
  #
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # NodePort:
  # âœ… Internal + external access
  # âœ… Port on each node (30000-32767)
  # âœ… Access via node IP
  # âŒ Not production-friendly (random ports)
  #
  # Example:
  # type: NodePort
  # ports:
  #   - port: 8084
  #     nodePort: 30084  # Accessible on each node
  #
  # Access:
  # curl http://node-ip:30084/auth/login
  # (From outside cluster)
  #
  # Use cases:
  # - Development (quick external access)
  # - Testing (no Ingress setup)
  # - Legacy apps (fixed ports)
  #
  # âŒ Issues:
  # - Random port range (30000+)
  # - Manual node IP management
  # - No load balancing (across nodes)
  #
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # LoadBalancer:
  # âœ… External access via cloud LB
  # âœ… Stable external IP
  # âœ… Automatic load balancing
  # âœ… Health checks
  # âŒ Expensive (one LB per service)
  #
  # Example:
  # type: LoadBalancer
  # ports:
  #   - port: 80
  #     targetPort: 8084
  #
  # Access:
  # curl http://external-ip/auth/login
  #
  # Cloud provider creates:
  # - AWS: Elastic Load Balancer (ELB)
  # - GCP: Cloud Load Balancer
  # - Azure: Azure Load Balancer
  #
  # Use cases:
  # - Public APIs (need external IP)
  # - Single-service apps
  # - Quick external exposure
  #
  # âŒ Issues:
  # - Expensive (one LB per service)
  # - No routing (L4 only)
  # - No TLS termination (do it yourself)
  #
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # ExternalName:
  # âœ… CNAME to external service
  # âœ… Alias external resources
  # âŒ No proxying (just DNS)
  #
  # Example:
  # type: ExternalName
  # externalName: api.example.com
  #
  # Use cases:
  # - Access external APIs (via stable name)
  # - Migration (old â†’ new services)
  # - Multi-cluster (service Ğ² another cluster)
  #
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # Headless (ClusterIP: None):
  # âœ… No load balancing
  # âœ… Direct pod IPs
  # âœ… DNS returns all pod IPs
  # âŒ No stable service IP
  #
  # Example:
  # type: ClusterIP
  # clusterIP: None
  #
  # Use cases:
  # - StatefulSets (direct pod access)
  # - Custom load balancing
  # - Peer discovery (pods find each other)
  #
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # TYPICAL ARCHITECTURE:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # External traffic:
  # Internet â†’ Ingress (TLS, routing) â†’ Gateway (ClusterIP)
  #                                      â†“
  #                                   Auth Service (ClusterIP)
  #                                      â†“
  #                                   PostgreSQL (ClusterIP)
  #
  # Why:
  # âœ… Single entry point (Ingress)
  # âœ… TLS termination (Ingress)
  # âœ… Routing (Ingress rules)
  # âœ… Internal services (ClusterIP)
  # âœ… Security (no direct exposure)
  #
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # KIND NOTES:
  # â•â•â•â•â•â•â•â•â•â•
  #
  # LoadBalancer Ğ² Kind:
  # - Requires MetalLB Ğ°Ğ±Ğ¾ cloud-provider-kind
  # - Otherwise stuck Ğ² Pending
  #
  # NodePort Ğ² Kind:
  # - Works out of box
  # - Access via localhost:nodePort
  #
  # ClusterIP Ğ² Kind:
  # - Internal only (default)
  # - Access via port-forward:
  #   kubectl port-forward svc/auth-service 8084:8084
  #   curl http://localhost:8084/auth/login

  selector:
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # POD SELECTOR
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # Which pods receive traffic Ğ²Ñ–Ğ´ this service
    #
    # Service finds pods Ğ· matching labels
    #
    # Process:
    # 1. Service created Ğ· selector
    # 2. K8s finds pods Ğ· labels: app=auth-service
    # 3. Creates Endpoints list (pod IPs + ports)
    # 4. Traffic sent to Endpoints (load balanced)
    #
    # Example:
    # Deployment creates 2 pods:
    # - Pod 1: IP 10.1.1.5, labels: app=auth-service
    # - Pod 2: IP 10.1.1.6, labels: app=auth-service
    #
    # Service endpoints:
    # - 10.1.1.5:8084
    # - 10.1.1.6:8084
    #
    # Traffic distribution:
    # Request 1 â†’ 10.1.1.5:8084 (Pod 1)
    # Request 2 â†’ 10.1.1.6:8084 (Pod 2)
    # Request 3 â†’ 10.1.1.5:8084 (Pod 1)
    # â†’ Round-robin load balancing
    #
    # MUST MATCH:
    # Deployment template.metadata.labels
    #
    # Deployment:
    # template:
    #   metadata:
    #     labels:
    #       app: auth-service  â† Must match
    #
    # Service:
    # selector:
    #   app: auth-service  â† Must match
    #
    # If mismatch:
    # - Service created (no error)
    # - No endpoints (empty list)
    # - Traffic fails (no destination)
    #
    # Check endpoints:
    # kubectl get endpoints auth-service
    # â†’ Should show pod IPs
    #
    # Empty endpoints:
    # NAME            ENDPOINTS   AGE
    # auth-service    <none>      5m
    # â†’ Check label matching!

    app: auth-service
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Primary Selector
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # Matches pods Ğ· label: app=auth-service
    #
    # Simple selector (one label):
    # âœ… Easy to understand
    # âœ… Works Ğ´Ğ»Ñ most cases
    # âœ… Matches all auth-service pods
    #
    # Multiple labels (more specific):
    # selector:
    #   app: auth-service
    #   version: v1
    #   environment: prod
    #
    # Matches ONLY pods Ğ· ALL labels:
    # âœ… Fine-grained control
    # âœ… Blue-green deployments
    # âœ… A/B testing
    # âŒ More complex
    #
    # Our case: Single label sufficient
    # All auth-service pods receive traffic

  ports:
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SERVICE PORTS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #
    # Port mappings (service port â†’ pod port)
    #
    # Can define multiple ports:
    # - port: 80, targetPort: 8080 (HTTP)
    # - port: 443, targetPort: 8443 (HTTPS)
    # - port: 9090, targetPort: 9090 (Metrics)

    - port: 8084
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Service Port
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Port where service listens
      #
      # Clients connect to:
      # http://auth-service:8084
      #            service name â†‘    â†‘ service port
      #
      # This is the "public" port (within cluster)
      #
      # Can differ Ğ²Ñ–Ğ´ container port:
      # - port: 80 (service)
      # - targetPort: 8080 (container)
      # â†’ http://service:80 â†’ container:8080
      #
      # Why same port (8084):
      # âœ… Simple (no confusion)
      # âœ… Consistent (same port everywhere)
      # âœ… Clear mapping (8084 â†’ 8084)
      #
      # When to differ:
      # - Standard ports (80 HTTP, 443 HTTPS)
      # - Port conflicts (multiple services)
      # - Legacy reasons (can't change app)

      targetPort: 8084
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Target Port (Container Port)
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Port on pod/container
      #
      # Where application actually listens
      # server.port=8084 (application.yml)
      #
      # Can be:
      # - Number: 8084
      # - Name: http (references containerPort name)
      #
      # Using name (better):
      # Container:
      # ports:
      #   - containerPort: 8084
      #     name: http
      #
      # Service:
      # ports:
      #   - port: 80
      #     targetPort: http  â† References name
      #
      # Benefits:
      # âœ… Change container port (update one place)
      # âœ… Self-documenting (clear purpose)
      # âœ… Multiple containers (same name, different port)
      #
      # Traffic flow:
      # Client â†’ Service:8084 â†’ Pod:8084 â†’ Container:8084
      #
      # Load balancing:
      # Request â†’ Service:8084
      #          â†“
      #          â”œâ†’ Pod 1 (10.1.1.5:8084)
      #          â”œâ†’ Pod 2 (10.1.1.6:8084)
      #          â””â†’ Pod 3 (10.1.1.7:8084)

      protocol: TCP
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Protocol
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Network protocol
      #
      # TCP (default):
      # - Reliable delivery
      # - Connection-oriented
      # - HTTP, HTTPS, gRPC
      #
      # UDP:
      # - Unreliable (faster)
      # - Connectionless
      # - DNS, streaming
      #
      # SCTP:
      # - Advanced (rarely used)
      # - Multi-homing
      # - Telecom

      name: http
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Port Name
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      #
      # Named port (optional)
      #
      # Benefits:
      # âœ… Self-documenting (clear purpose)
      # âœ… Prometheus discovery (port=http)
      # âœ… Network policies (allow http)
      # âœ… Ingress rules (backend=http)
      #
      # Common names:
      # - http, https (web traffic)
      # - grpc (gRPC services)
      # - metrics (Prometheus)
      # - health (health checks)
      # - admin (admin interface)
      #
      # Multiple ports example:
      # ports:
      #   - port: 8084
      #     name: http
      #   - port: 9090
      #     name: metrics
      #   - port: 8085
      #     name: admin

  sessionAffinity: None
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # SESSION AFFINITY
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # Sticky sessions (session persistence)
  #
  # Options:
  # â•â•â•â•â•â•â•â•
  #
  # None (default):
  # âœ… No session affinity
  # âœ… Random load balancing
  # âœ… Requests from same client â†’ different pods
  #
  # Load balancing:
  # Client A, Request 1 â†’ Pod 1
  # Client A, Request 2 â†’ Pod 2
  # Client A, Request 3 â†’ Pod 1
  # â†’ Random distribution
  #
  # Benefits:
  # âœ… Best load distribution
  # âœ… No hot spots (one pod overloaded)
  # âœ… Stateless apps (no session data Ğ² pods)
  #
  # Use cases:
  # - Stateless APIs (JWT auth)
  # - Microservices (no server state)
  # - Modern apps (session Ğ² Redis/DB)
  #
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # ClientIP:
  # âœ… Session affinity enabled
  # âœ… Same client IP â†’ same pod
  # âœ… Sticky sessions
  #
  # Configuration:
  # sessionAffinity: ClientIP
  # sessionAffinityConfig:
  #   clientIP:
  #     timeoutSeconds: 10800  # 3 hours
  #
  # Load balancing:
  # Client A (IP: 1.2.3.4):
  #   Request 1 â†’ Pod 1
  #   Request 2 â†’ Pod 1  â† Same pod
  #   Request 3 â†’ Pod 1  â† Same pod
  #
  # Client B (IP: 5.6.7.8):
  #   Request 1 â†’ Pod 2
  #   Request 2 â†’ Pod 2  â† Same pod
  #
  # Benefits:
  # âœ… Session preserved (same pod)
  # âœ… No session replication needed
  # âœ… Better caching (data locality)
  #
  # Drawbacks:
  # âŒ Uneven load (hot clients)
  # âŒ Not resilient (pod dies â†’ session lost)
  # âŒ Behind NAT (many clients, same IP)
  #
  # Use cases:
  # - Legacy apps (server-side sessions)
  # - WebSocket connections (persistent)
  # - Stateful protocols (FTP, RTMP)
  #
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # WHY None FOR AUTH SERVICE:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # Auth Service = Stateless:
  # âœ… JWT tokens (no server sessions)
  # âœ… Refresh tokens Ğ² Redis (shared)
  # âœ… No in-memory state
  # âœ… Can route to any pod
  #
  # Benefits:
  # âœ… Perfect load balancing
  # âœ… High availability (pod dies, others serve)
  # âœ… Easy scaling (add/remove pods)
  # âœ… Rolling updates (zero downtime)
  #
  # Stateless authentication:
  # 1. Client sends request Ğ· JWT
  # 2. Any pod can validate (public key)
  # 3. No need same pod (stateless)
  #
  # Refresh tokens:
  # 1. Client sends refresh token
  # 2. Any pod checks Redis (shared storage)
  # 3. Returns new tokens
  #
  # If stateful:
  # âŒ Session Ğ² pod memory
  # âŒ Must route to same pod
  # âŒ sessionAffinity: ClientIP needed
  # âŒ Poor scalability
  #
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # ALTERNATIVES (not Ğ² Service):
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #
  # Application-level affinity:
  # - Consistent hashing (user ID â†’ pod)
  # - Custom routing (API Gateway)
  # - Session replication (Hazelcast, Redis)
  #
  # Ingress-level affinity:
  # - Cookie-based sticky sessions
  # - Ingress annotations (NGINX)
  # - Better than IP-based (behind NAT)
  #
  # Example (NGINX Ingress):
  # annotations:
  #   nginx.ingress.kubernetes.io/affinity: "cookie"
  #   nginx.ingress.kubernetes.io/session-cookie-name: "route"
  #   nginx.ingress.kubernetes.io/session-cookie-expires: "172800"
  #   nginx.ingress.kubernetes.io/session-cookie-max-age: "172800"
  #
  # Benefits:
  # âœ… Cookie-based (works Ğ·Ğ° NAT)
  # âœ… Survives IP changes
  # âœ… More reliable